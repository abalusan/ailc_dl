{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch\n",
    "\n",
    "Dynamic computation graph - key advantage / difference overtensorflow. Very useful for RNNs. Also, enables changing the training batch size and etc is possible during training. \n",
    "    Each line of code dynamically adds to a graph.\n",
    "Implemented in python - so debugging is better\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# requires_grad -> Tell pytorch that this nodes should be updated w/ gradients\n",
    "x = torch.ones((2,2), requires_grad=True)\n",
    "y = x + 2\n",
    "z = 2*y*y\n",
    "out = z.mean()\n",
    "\n",
    "#print(out)\n",
    "\n",
    "#generates gradients d(out)/dx and propogates back to x for update\n",
    "out.backward()\n",
    "#gradient of X w/ which the variable would be updated\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#1-D tensor. \n",
    "a = torch.tensor([2,2,1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 4],\n",
      "        [3, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#2-D tensor\n",
    "b = torch.tensor([[2,1,4],[3,5,6]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#size of tensors\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Get height or number of rows of b\n",
    "print(b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Float tensor: values in the tensors are floats\n",
    "c = torch.FloatTensor([[2,1,4],[2,5,6]])\n",
    "#double tensor: values in the tensors are doubles\n",
    "d = torch.DoubleTensor([2,2,1])\n",
    "#alternative way: d=torch.tensor([2,2,1], dtype=torch.double). lly for float as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 4.],\n",
      "        [2., 5., 6.]])\n",
      "torch.float32\n",
      "tensor(3.3333)\n",
      "tensor(1.9664)\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print(c.dtype)\n",
    "print(c.mean())\n",
    "print(c.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 1.], dtype=torch.float64)\n",
      "torch.float64\n",
      "tensor(1.6667, dtype=torch.float64)\n",
      "tensor(0.5774, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(d)\n",
    "print(d.dtype)\n",
    "print(d.mean())\n",
    "print(d.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-shaping tensors - Extremely important\n",
    "\n",
    "The method to reshape a tensor is \"view\". Give dimensions to reshape to the view func. If -1 for a dimension, that would be inferred by python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [1],\n",
      "        [4],\n",
      "        [3],\n",
      "        [5],\n",
      "        [6]])\n",
      "tensor([2, 1, 4, 3, 5, 6])\n",
      "tensor([[2, 1],\n",
      "        [4, 3],\n",
      "        [5, 6]])\n",
      "tensor([[2, 1, 4, 3, 5, 6]])\n",
      "torch.Size([1, 6])\n",
      "\n",
      "\n",
      "torch.Size([2, 3, 4])\n",
      "tensor([[[0.8612, 0.5959, 0.6172, 0.2339],\n",
      "         [0.9311, 0.5716, 0.8916, 0.3686],\n",
      "         [0.1235, 0.0397, 0.4659, 0.9374]],\n",
      "\n",
      "        [[0.5254, 0.7874, 0.9019, 0.1523],\n",
      "         [0.7008, 0.6153, 0.4355, 0.2603],\n",
      "         [0.9818, 0.9065, 0.3279, 0.8767]]])\n",
      "tensor([[0.8612, 0.5959, 0.6172, 0.2339, 0.9311, 0.5716, 0.8916, 0.3686, 0.1235,\n",
      "         0.0397, 0.4659, 0.9374],\n",
      "        [0.5254, 0.7874, 0.9019, 0.1523, 0.7008, 0.6153, 0.4355, 0.2603, 0.9818,\n",
      "         0.9065, 0.3279, 0.8767]])\n"
     ]
    }
   ],
   "source": [
    "print(b.view(-1,1))\n",
    "print(b.view(6))\n",
    "print(b.reshape(-1,2))\n",
    "\n",
    "b = b.view(1,-1)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "\n",
    "#Create 3D tensor with 2 channels, 3 rows, 4 columns (channels, rows, columns)\n",
    "three_dim = torch.rand(2,3,4)\n",
    "print(\"\\n\")\n",
    "print(three_dim.shape)\n",
    "print(three_dim)\n",
    "print(three_dim.view(2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4081, 0.1049, 0.7361, 0.2212],\n",
      "        [0.8706, 0.3780, 0.1446, 0.2851],\n",
      "        [0.8479, 0.1715, 0.1173, 0.6180],\n",
      "        [0.5915, 0.8875, 0.5814, 0.6090]])\n"
     ]
    }
   ],
   "source": [
    "#Matrix w/ random numbers in range [0,1] (math notation)\n",
    "r2 =torch.rand(4,4)\n",
    "#r3 = torch.rand([4,4])\n",
    "print(r2)\n",
    "#print(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9817, -0.0725,  0.5160, -0.0769],\n",
      "        [ 2.7607, -1.5576,  0.9992,  0.3418],\n",
      "        [ 0.8011,  0.1054,  0.2290, -0.1287],\n",
      "        [-1.1065,  0.4416, -0.3332,  0.3106]])\n"
     ]
    }
   ],
   "source": [
    "#Matrix w/ random numbers generated from a normal distribution with mean 0 and variance 1\n",
    "r4 = torch.randn(4,4)\n",
    "print(r4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 8, 8, 8, 7])\n",
      "torch.int64\n",
      "tensor([[9, 8, 8, 8],\n",
      "        [6, 7, 6, 7],\n",
      "        [9, 6, 6, 9]])\n",
      "3\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Create an array of 5 integers from values b/w 6 and 9 (below, 10 is exclusive)\n",
    "#Note: The size must be given as a tuple\n",
    "int_arr = torch.randint(6,10,(5,))\n",
    "twod_ir = torch.randint(6,10,(3,4))\n",
    "print(int_arr)\n",
    "print(int_arr.dtype)\n",
    "print(twod_ir)\n",
    "\n",
    "#Number of elements: len gives out only the rows, while numel gives out all the elements in the array\n",
    "print(len(twod_ir))\n",
    "print(torch.numel(twod_ir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]) tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Matrix of zeros and ones.  Default dtype is float \n",
    "z = torch.zeros(3,3,dtype=torch.long)\n",
    "o = torch.ones(3,3,dtype=torch.float)\n",
    "\n",
    "print(z, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8087,  0.5464, -0.3969, -1.2258],\n",
      "        [ 0.8609,  1.6271, -0.7424, -0.0041],\n",
      "        [-1.4082,  0.0473, -1.4184,  0.4589],\n",
      "        [ 0.2762, -0.4963, -1.2571,  0.6095]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Generate a random array whose size matches another array r2\n",
    "r2_like = torch.randn_like(r2, dtype=torch.double)\n",
    "print(r2_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4005,  0.6513,  0.3392, -1.0046],\n",
      "        [ 1.7315,  2.0051, -0.5978,  0.2810],\n",
      "        [-0.5603,  0.2188, -1.3011,  1.0769],\n",
      "        [ 0.8678,  0.3912, -0.6757,  1.2185]], dtype=torch.float64)\n",
      "tensor([[-0.4005,  0.6513,  0.3392, -1.0046],\n",
      "        [ 1.7315,  2.0051, -0.5978,  0.2810],\n",
      "        [-0.5603,  0.2188, -1.3011,  1.0769],\n",
      "        [ 0.8678,  0.3912, -0.6757,  1.2185]], dtype=torch.float64)\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#Adding two tensors\n",
    "reg_add = r2 + r2_like\n",
    "t_add = torch.add(r2,r2_like)\n",
    "\n",
    "print(reg_add)\n",
    "print(t_add)\n",
    "#Element-wise equivalance check. Result will be a tesnor of bools\n",
    "print(reg_add==t_add)\n",
    "# Returns bool\n",
    "print(torch.equal(reg_add, t_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4005,  0.6513,  0.3392, -1.0046],\n",
      "        [ 1.7315,  2.0051, -0.5978,  0.2810],\n",
      "        [-0.5603,  0.2188, -1.3011,  1.0769],\n",
      "        [ 0.8678,  0.3912, -0.6757,  1.2185]], dtype=torch.float64)\n",
      "tensor([[0.4081, 0.1049, 0.7361, 0.2212],\n",
      "        [0.8706, 0.3780, 0.1446, 0.2851],\n",
      "        [0.8479, 0.1715, 0.1173, 0.6180],\n",
      "        [0.5915, 0.8875, 0.5814, 0.6090]])\n",
      "tensor([[-0.4005,  0.6513,  0.3392, -1.0046],\n",
      "        [ 1.7315,  2.0051, -0.5978,  0.2810],\n",
      "        [-0.5603,  0.2188, -1.3011,  1.0769],\n",
      "        [ 0.8678,  0.3912, -0.6757,  1.2185]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(r2.add(r2_like))\n",
    "print(r2)\n",
    "#In-place addition. Addition performed and r2 is updated w/ result\n",
    "print(r2.add_(r2_like))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6513, 2.0051, 0.2188, 0.3912])\n",
      "tensor([[-0.4005,  0.6513],\n",
      "        [ 1.7315,  2.0051],\n",
      "        [-0.5603,  0.2188],\n",
      "        [ 0.8678,  0.3912]])\n",
      "tensor(1.0769)\n",
      "<class 'torch.Tensor'>\n",
      "1.0769110918045044 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#Slicing\n",
    "print(r2[:,1]) # all rows of column 1\n",
    "print(r2[:,:2]) # all rows and columns until 2 ( upper bound not inclusive in python)\n",
    "num_ten = r2[2,3] # Element at 2nd row and 3rd column\n",
    "print(num_ten)\n",
    "#numten is still a tensor which means it is a class object. You can get the data out of it as follows. \n",
    "print(type(num_ten))\n",
    "print(num_ten.item(), type(num_ten.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "#Numpy Bridge\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b= a.numpy()\n",
    "print(b)\n",
    "#Numpy arrays are AFFECTED by the operations on the torch tensor. In the example below b changes as well due to addition perfromed on a. \n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Similar behavior other way around\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "# add 1 to a and update a w/ the result\n",
    "np.add(a,1,out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move tensor to GPU to speed up calculations. WE DONT HAVE CUDA\n",
    "#r2 = r2.cuda()\n",
    "#print(r2)\n",
    "#If cuda was enables,  the tensor is returned with \"device='cuda:0'\"\n",
    "# tesnor([1,2,3], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provides easy switching to CPU and GPU. The command below returns a boolean which we can use. So need to write separate codes for CPU and GPU\n",
    "#CUDA = torch.cuda.is_available() \n",
    "#if CUDA: \n",
    "#   add_result = add_result.cuda()\n",
    "#   print(add_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 1]\n",
      "tensor([2, 3, 4, 1]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Convert list to a tensor. List can be multidimentsional\n",
    "a= [2,3,4,1]\n",
    "print(a)\n",
    "to_list = torch.tensor(a)\n",
    "print(to_list, to_list.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7970,  0.2046, -0.6591, -0.6871,  0.3704],\n",
      "        [ 0.5875,  0.1893, -0.9347, -0.6139,  1.0901],\n",
      "        [ 0.3091,  1.1595, -1.7353,  0.3249,  0.9774]])\n",
      "tensor([[ 1.0854, -0.7396, -0.7283, -0.3023,  0.3883],\n",
      "        [-1.6359,  0.6533, -1.1465, -0.9978, -1.2423],\n",
      "        [-0.0935,  0.4088, -2.6049,  0.2012, -0.1268]])\n",
      "tensor([[ 1.7970,  0.2046, -0.6591, -0.6871,  0.3704],\n",
      "        [ 0.5875,  0.1893, -0.9347, -0.6139,  1.0901],\n",
      "        [ 0.3091,  1.1595, -1.7353,  0.3249,  0.9774],\n",
      "        [ 1.0854, -0.7396, -0.7283, -0.3023,  0.3883],\n",
      "        [-1.6359,  0.6533, -1.1465, -0.9978, -1.2423],\n",
      "        [-0.0935,  0.4088, -2.6049,  0.2012, -0.1268]])\n",
      "tensor([[ 1.7970,  0.2046, -0.6591, -0.6871,  0.3704,  1.0854, -0.7396, -0.7283,\n",
      "         -0.3023,  0.3883],\n",
      "        [ 0.5875,  0.1893, -0.9347, -0.6139,  1.0901, -1.6359,  0.6533, -1.1465,\n",
      "         -0.9978, -1.2423],\n",
      "        [ 0.3091,  1.1595, -1.7353,  0.3249,  0.9774, -0.0935,  0.4088, -2.6049,\n",
      "          0.2012, -0.1268]])\n"
     ]
    }
   ],
   "source": [
    "#Tensor concatenation\n",
    "f1 = torch.randn(3,5)\n",
    "print(f1)\n",
    "s1 =  torch.randn(3,5)\n",
    "print(s1)\n",
    "\n",
    "#Concat along rows\n",
    "c1 = torch.cat([f1,s1])\n",
    "print(c1)\n",
    "\n",
    "#Concat along columns\n",
    "c2 = torch.cat([f1,s1],1)\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "torch.Size([4, 1])\n",
      "tensor([[[1]],\n",
      "\n",
      "        [[2]],\n",
      "\n",
      "        [[3]],\n",
      "\n",
      "        [[4]]])\n",
      "torch.Size([4, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "#Adding dimensions to a tensor\n",
    "tensor_1d = torch.tensor([1,2,3,4])\n",
    "tensor_2d = torch.unsqueeze(tensor_1d,0) #add another dimension along 0 axis\n",
    "print(tensor_1d)\n",
    "print(tensor_2d)\n",
    "print(tensor_1d.shape)\n",
    "print(tensor_2d.shape)\n",
    "\n",
    "tensor_2dc = torch.unsqueeze(tensor_1d,1) #add another dimension along 1 axis\n",
    "print(tensor_2dc)\n",
    "print(tensor_2dc.shape)\n",
    "\n",
    "tensor_3d = torch.unsqueeze(tensor_2dc, 1) \n",
    "print(tensor_3d)\n",
    "print(tensor_3d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTO GRAD in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x7fff6c2b88e0>\n",
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x7fff6c2bb6d0>\n"
     ]
    }
   ],
   "source": [
    "#If require_grad = True, the tensor object keeps track of how it was created\n",
    "x = torch.tensor([1.,2.,3.], requires_grad=True)\n",
    "y = torch.tensor([4.,5.,6.], requires_grad=True)\n",
    "z = x + y\n",
    "print(z)\n",
    "#z keeps track of how it was created which is as a result of addition og x & y. (it know that it wasn't read-in from a file)\n",
    "print(z.grad_fn)\n",
    "#We can go further and the objects still keep track\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "#Now we can backprop on s, this calculates all the gradients in the dynamic computation graph\n",
    "s.backward()\n",
    "#Now if we want ds/dx, we do it as follows\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<AddBackward0 object at 0x7fff6c187250>\n",
      "None\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#By default, requires_grad is False\n",
    "x = torch.randn(2,2)\n",
    "y = torch.randn(2,2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "#z doesn't remember/track how it was created since the underlying tesnors don't have requires_grad=True and we cannot backprop\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "\n",
    "#Now we can set requires_grad on the existing tensors as follows\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "#Now z tracks how it was created as the requires grad is set on i/p\n",
    "z = x + y\n",
    "print(z.grad_fn)\n",
    "\n",
    "#In conclusion, if i/p's have required grad set to True on them, all the variables created using these i/ps will have require grad set to True\n",
    "\n",
    "# We are detaching z and storing in new tensor. Detach returns a tensor whose data will be same as z but all the computation history and how it was created is forgot\n",
    "new_z = z.detach()\n",
    "print(new_z.grad_fn)\n",
    "\n",
    "#Stop autograd from tracking history in tensors. This is useful in transfer learning. \n",
    "# We are just printing the value of requires_grad\n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "\n",
    "# Here we are stopping the tracking with this setting\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x7fff6c219090>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "#Causual example of building a dynamic computation graph and backprop-ing the gradients \n",
    "x = torch.ones(2,2,requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z,out)\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".course_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
